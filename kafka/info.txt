Producer - application that send message (data) to Kafka. It should be small or medium sized piece of data
Consumer - application that receives message data from Kafka
Broker - Kafka Server
Cluster - Group of computers sharing workload for o common purpose
Topic - A name of a Kafka stream
Partitions - Part of the topic, numer of machines of topic, where message are broken into number of machines
Offset - Unique id for a message within the partition. Sequence id given to messages they arrive in a partition  
Consumer groups - A group o consumers acting as a single logical unit 

PRODUCER --- send message to Kafka Server ---> 					---> message     
												 KAFKA SERVER							 	CONSUMER
PRODUCER --- send message to Kafka Server ---> 					---> request for message

Global unique indentifier of a message
TOPIC NAME -> PARTICIONS NUMBER -> OFFSET

The number of consumers in group is equal to number of patrtitions on the topic
Increasing partisions and consumers in group allows to achive scalability


Kafka Use Cases
Kafka helps teams that need reliable, organized storage at scale.
It can handle large amounts of data making it ideal for high volume projects.
Teams can easily scale and multiple subscribers can consume the data without impacting performance.
In contrast to Active MQ, Kafka is a distributed system meant for processing a huge amount of data. We can use it for traditional messaging as well as:
- website activity tracking
- metrics
- log aggregation
- stream processing
- event sourcing
- commit logs

ActiveMQ Use Cases
Active MQ is one of the traditional message brokers, whose goal is to ensure data exchange between applications in a safe and reliable way.
Never miss a message and process each one exactly once. This works well for financial information, deposits, withdrawals, and more.
It deals with a small amount of data and is therefore specialized for well-defined message formats and transactional messaging.
ActiveMQ works well for small amounts of data in a multi-application architecture.
It’s easy and cost effective to get up and running and complex message routing can be set up and more easily maintained.
Also, for teams needing exactly-once delivery, ActiveMQ is extremely reliable.

Producer -> ActiveMQ broker (Queue point-to-point) -> Consumer
Producer -> ActiveMQ broker (Topic pub/sub) -> Consumer



========
## kafka
========
## lista topiców
================
bin/kafka-topics.sh --zookeeper ADRES_ZOOKEEPERZ_PORTEM --list

bin/kafka-topics.sh --zookeeper leader.cdt.dcos:2181/dcos-service-kafka-macod-dev01 --list

===================
## zawartosc topicu
===================
bin/kafka-console-consumer.sh --bootstrap-server ADDRESS_KAFKI_WRAZ_Z_PORTEM --topic NAZWA_TOPICU_KTORY_CHCESZ_PRZEJRZEC --from-beginning --property print.key=true --property key.separator="-"

bin/kafka-console-consumer.sh --bootstrap-server dev-macod-brokers.imshealthcloud.net:9626 --topic nuke-dev.bridge-corrections --from-beginning --property print.key=true --property key.separator="-"

bin/kafka-console-consumer.sh --topic nuke-test.importer-commands --from-beginning  --bootstrap-server dev-macod-brokers.imshealthcloud.net:9626 
